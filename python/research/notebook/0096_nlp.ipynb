{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "998aa4e6-d2e9-4673-8bb3-51a97745ba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0096_nlp\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68cda961-535e-40e9-af8f-f610e60a01c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenProcessor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._stemmer = None\n",
    "        self._stop_words = None\n",
    "        self._lemmatizer = None\n",
    "        self._ner_tagger = None\n",
    "        self._pos_tagger = None\n",
    "\n",
    "    @property\n",
    "    def stemmer(self):\n",
    "        if self._stemmer is None:\n",
    "            self._stemmer = PorterStemmer()\n",
    "        return self._stemmer\n",
    "\n",
    "    def stem(self, words):\n",
    "        stemmer = self.stemmer\n",
    "\n",
    "        res = []\n",
    "        for w in words:\n",
    "            rw = stemmer.stem(w)\n",
    "            res.append(rw)\n",
    "\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def stop_words(self):\n",
    "        if self._stop_words is None:\n",
    "            self._stop_words = set(stopwords.words('english'))\n",
    "        return self._stop_words\n",
    "\n",
    "    def clean_stop_words(self, words):\n",
    "        stop_words = self.stop_words\n",
    "\n",
    "        res = []\n",
    "        for w in words:\n",
    "            w_test = w[0] if isinstance(w, tuple) else w\n",
    "            if w_test.lower() not in stop_words:\n",
    "                res.append(w)\n",
    "\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def lemmatizer(self):\n",
    "        if self._lemmatizer is None:\n",
    "            self._lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        return self._lemmatizer\n",
    "\n",
    "    def lemmatize(self, words):\n",
    "        lemmatizer = self.lemmatizer\n",
    "\n",
    "        res = []\n",
    "        for w in words:\n",
    "            word = lemmatizer.lemmatize(w.lower())\n",
    "            res.append(word)\n",
    "\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_digits(words):\n",
    "        return [w for w in words if not w.isdigit()]\n",
    "\n",
    "    @staticmethod\n",
    "    def upper(words):\n",
    "        return [w.upper() for w in words]\n",
    "\n",
    "    @staticmethod\n",
    "    def lower(words):\n",
    "        return [w.lower() for w in words]\n",
    "\n",
    "    @staticmethod\n",
    "    def sentence(words):\n",
    "        return \" \".join(words)\n",
    "\n",
    "\n",
    "class TextProcessor:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_punctuations(text):\n",
    "        return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    @staticmethod\n",
    "    def to_words(text):\n",
    "        return word_tokenize(text)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_sentences(text):\n",
    "        return sent_tokenize(text)\n",
    "\n",
    "\n",
    "class NLPProcessor:\n",
    "\n",
    "    def __init__(self, text_kwargs={}, token_kwargs={}):\n",
    "\n",
    "        self.txtp = TextProcessor(**text_kwargs)\n",
    "        self.tokp = TokenProcessor(**token_kwargs)\n",
    "\n",
    "    def clean_words(self, sentence):\n",
    "        txtp = self.txtp\n",
    "        tokp = self.tokp\n",
    "\n",
    "        res = txtp.clean_punctuations(sentence)\n",
    "\n",
    "        words = txtp.to_words(res)\n",
    "        words = tokp.clean_digits(words)\n",
    "        words = tokp.lemmatize(words)\n",
    "        words = tokp.upper(words)\n",
    "        words = tokp.clean_stop_words(words)\n",
    "\n",
    "        return words\n",
    "\n",
    "    def clean_sentence(self, sentence):\n",
    "        words = self.clean_words(sentence)\n",
    "\n",
    "        return self.tokp.sentence(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbdae084-f0e5-4c2e-bee3-e59d0458fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpp = NLPProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "321cab1d-9fa3-4588-af78-4556e8fd0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"Hello there! How're things going? It's been a long time.\"\n",
    "s2 = \"the red riding hood got lost in the forest\"\n",
    "s3 = \"I am think of moving to a new country. But having a hard time deciding\"\n",
    "s4 = \"what should I do when I see a new dress I like but cost too much?\"\n",
    "\n",
    "df = pd.DataFrame(data={\n",
    "    \"event_id\": [1, 2, 3, 4],\n",
    "    \"sentence\": [s1, s2, s3, s4]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60b09d9c-498b-47f4-b27f-0c9d96f78dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean\"] = df[\"sentence\"].apply(lambda x: nlpp.clean_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb370326-60a9-4201-a644-80dcd587f866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hello there! How're things going? It's been a ...</td>\n",
       "      <td>HELLO HOWRE THING GOING LONG TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>the red riding hood got lost in the forest</td>\n",
       "      <td>RED RIDING HOOD GOT LOST FOREST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I am think of moving to a new country. But hav...</td>\n",
       "      <td>THINK MOVING NEW COUNTRY HARD TIME DECIDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>what should I do when I see a new dress I like...</td>\n",
       "      <td>SEE NEW DRESS LIKE COST MUCH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id                                           sentence  \\\n",
       "0         1  Hello there! How're things going? It's been a ...   \n",
       "1         2         the red riding hood got lost in the forest   \n",
       "2         3  I am think of moving to a new country. But hav...   \n",
       "3         4  what should I do when I see a new dress I like...   \n",
       "\n",
       "                                         clean  \n",
       "0            HELLO HOWRE THING GOING LONG TIME  \n",
       "1              RED RIDING HOOD GOT LOST FOREST  \n",
       "2  THINK MOVING NEW COUNTRY HARD TIME DECIDING  \n",
       "3                 SEE NEW DRESS LIKE COST MUCH  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f72a9645-eb6d-4a61-875e-c9d7cb561a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 23)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.7, max_features=200,\n",
    "                                   min_df=0.2, use_idf=True)\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['clean'].values)\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ffeb1ee-2b9e-4911-bff5-d779f0b3473e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x23 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 25 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2bea9f2-c9ed-4006-b157-9564a9d099dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "['cost', 'country', 'deciding', 'dress', 'forest', 'going', 'got', 'hard', 'hello', 'hood', 'howre', 'like', 'long', 'lost', 'moving', 'much', 'new', 'red', 'riding', 'see', 'thing', 'think', 'time']\n"
     ]
    }
   ],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "print(len(terms))\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1694607b-4a13-430c-8cb9-c83db83057a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 2\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d68c8ba-f16c-44c7-b71d-13031b758ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3\n",
      "1    1\n",
      "Name: cluster, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "clusters = km.labels_.tolist()\n",
    "df['cluster'] = clusters\n",
    "print(df['cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4decc92e-3729-4e98-bb81-06d8c95853ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hello there! How're things going? It's been a ...</td>\n",
       "      <td>HELLO HOWRE THING GOING LONG TIME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>the red riding hood got lost in the forest</td>\n",
       "      <td>RED RIDING HOOD GOT LOST FOREST</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I am think of moving to a new country. But hav...</td>\n",
       "      <td>THINK MOVING NEW COUNTRY HARD TIME DECIDING</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>what should I do when I see a new dress I like...</td>\n",
       "      <td>SEE NEW DRESS LIKE COST MUCH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id                                           sentence  \\\n",
       "0         1  Hello there! How're things going? It's been a ...   \n",
       "1         2         the red riding hood got lost in the forest   \n",
       "2         3  I am think of moving to a new country. But hav...   \n",
       "3         4  what should I do when I see a new dress I like...   \n",
       "\n",
       "                                         clean  cluster  \n",
       "0            HELLO HOWRE THING GOING LONG TIME        0  \n",
       "1              RED RIDING HOOD GOT LOST FOREST        1  \n",
       "2  THINK MOVING NEW COUNTRY HARD TIME DECIDING        0  \n",
       "3                 SEE NEW DRESS LIKE COST MUCH        0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99095208-c0a2-4b77-b8d6-38b41425178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0:\n",
      "\twords:\n",
      "\t\ttime\n",
      "\t\tnew\n",
      "\t\tlong\n",
      "\t\tdress\n",
      "\t\tgoing\n",
      "\ttitles:\n",
      "\t\tHELLO HOWRE THING GOING LONG TIME\n",
      "\t\tTHINK MOVING NEW COUNTRY HARD TIME DECIDING\n",
      "\t\tSEE NEW DRESS LIKE COST MUCH\n",
      "\t\t...\n",
      "cluster 1:\n",
      "\twords:\n",
      "\t\thood\n",
      "\t\triding\n",
      "\t\tred\n",
      "\t\tforest\n",
      "\t\tlost\n",
      "\ttitles:\n",
      "\t\tRED RIDING HOOD GOT LOST FOREST\n",
      "\t\t...\n"
     ]
    }
   ],
   "source": [
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "for i in range(num_clusters):\n",
    "    print(f\"cluster {i}:\")\n",
    "    print(f\"\\twords:\")\n",
    "    for ind in order_centroids[i, :5]:\n",
    "        print(f\"\\t\\t{terms[ind]}\")\n",
    "    print(f\"\\ttitles:\")\n",
    "    for title in df[df['cluster'] == i]['clean'].values.tolist()[:5]:\n",
    "        print(f\"\\t\\t{title}\")\n",
    "    print(f\"\\t\\t...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcae0b4-ef8a-4f91-ab90-1fab05c7d0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
